{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoEzIPngSAHj0L+/uDOcx0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/recife25/AGSAdvGenAIBuildingLLMAppProject/blob/main/AI_Powered_HR_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Felipe Ruiz\n",
        "\n",
        "===AI Power HR Assistant Project===\n",
        "\n",
        "AGS Advance Generative AI: Building LLM app\n",
        "\n",
        "Nestle hr policy pdf file\n",
        "\n",
        "gradio doc init\n",
        "\n",
        "course project ai powered hr assistant"
      ],
      "metadata": {
        "id": "RXgJKq5Du2x5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5_c3Nt7htrW",
        "outputId": "dd4db011-afe4-4cc1-ef18-1f9490da8185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.87.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.13)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2, faiss-cpu\n",
            "Successfully installed PyPDF2-3.0.1 faiss-cpu-1.11.0\n"
          ]
        }
      ],
      "source": [
        "pip install openai gradio PyPDF2 faiss-cpu tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc808c92"
      },
      "source": [
        "#code sets the openai api key - which is secret - setting up programming env\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PyPDF2 library helps with the extraction of pdf files - programming env\n",
        "import PyPDF2"
      ],
      "metadata": {
        "id": "_rGOkBoxiB2N"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extract the nestle org pdf file - processing text documents - the pdf file\n",
        "def extract_text_from_pdf(file_path):\n",
        "  text = \"\"\n",
        "  with open(file_path, \"rb\") as file:\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "    for page in reader.pages:\n",
        "      text += page.extract_text()\n",
        "  return text"
      ],
      "metadata": {
        "id": "HuAqL37JidtZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split the Text into chunks - cont processing text documents - the chunks\n",
        "def split_text(text, max_tokens=500):\n",
        "    sentences = text.split('. ')\n",
        "    chunks, current_chunk = [], ''\n",
        "    for sentence in sentences:\n",
        "        if len(current_chunk.split()) + len(sentence.split()) <= max_tokens:\n",
        "            current_chunk += sentence + '. '\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + '. '\n",
        "    chunks.append(current_chunk.strip())\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "rnQ93MTal-0v"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#embed the text - setting chunks into sets prior to vectoring - the lego parts\n",
        "\n",
        "import openai\n",
        "\n",
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "    client = openai.OpenAI()\n",
        "    response = client.embeddings.create(input=[text], model=model)\n",
        "    return response.data[0].embedding"
      ],
      "metadata": {
        "id": "wtb6tN1veofK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the vector store - the vector representation\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "def build_faiss_index(chunks):\n",
        "    embeddings = [get_embedding(chunk) for chunk in chunks]\n",
        "    dim = len(embeddings[0])\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(np.array(embeddings).astype('float32'))\n",
        "    return index, embeddings\n"
      ],
      "metadata": {
        "id": "cKTCKOkIi0Ln"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build the search + answer system - the Q&A ask me anything ?\n",
        "import faiss\n",
        "import numpy as np\n",
        "import openai\n",
        "\n",
        "def search_and_respond(user_query, chunks, index, embeddings, top_k=1):\n",
        "    query_embedding = get_embedding(user_query)\n",
        "    D, I = index.search(np.array([query_embedding]).astype('float32'), top_k)\n",
        "    context = \" \".join([chunks[i] for i in I[0]])\n",
        "\n",
        "    client = openai.OpenAI()\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nUser Question: {user_query}\\n\\nAnswer:\"}]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "SRlG1v0OjAtw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e2e9944"
      },
      "source": [
        "#Replace with the actual path to your PDF file - forgot pdf file needs colab files path\n",
        "file_path = '/content/1728286846_the_nestle_hr_policy_pdf_2012.pdf'\n",
        "text = extract_text_from_pdf(file_path)\n",
        "chunks = split_text(text)\n",
        "index, embeddings = build_faiss_index(chunks)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create gradio chat interface - open the pdf file briefly read it , and follow with\n",
        "#Q&A session using the Nestle HR Assistant\n",
        "import gradio as gr\n",
        "\n",
        "def chatbot_interface(query):\n",
        "    return search_and_respond(query, chunks, index, embeddings)\n",
        "\n",
        "iface = gr.Interface(fn=chatbot_interface, inputs=\"text\", outputs=\"text\", title=\"Nestlé HR Assistant\")\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "H7qaAvurjPMi",
        "outputId": "0679a11a-1990-4ea0-f64d-ca4d0cd28b7f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://75b2a1c0ca42890eee.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://75b2a1c0ca42890eee.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sample Q&A exchange:\n",
        "Felipe Ruiz\n",
        "Project AI-Powered-HR-Assistant\n",
        "\n",
        "======\n",
        "\n",
        "section: introduction\n",
        "provide me with a brief summary of keypoints in the letter to nestle hr by Jean-Marc Duvoisin Deputy Executive Vice President\n",
        "\n",
        "output:\n",
        "In the introduction of the Nestlé Human Resources Policy, Jean-Marc Duvoisin emphasizes the importance of employees to the success of the company. He highlights the role of line managers in creating a supportive work environment and developing future leaders. Duvoisin outlines the responsibilities of HR managers in guiding line managers to optimize employee performance and achieve business goals. He also mentions the HR structure based on specialized services, business partnerships, and employee services, all working towards the common goal of ensuring the long-term success of the company through the effective management and development of employees.\n",
        "\n",
        "\n",
        "======\n",
        "\n",
        "Can you outline key points of these letter, provide me with numberic bullets\n",
        "\n",
        "output:\n",
        "1. The Nestlé Human Resources Policy is a mandatory policy for all employees, approved by the Executive Board of Nestlé S.A. in September 2012.\n",
        "2. The policy emphasizes the importance of employees as the key to Nestlé's success and outlines guidelines for effective Human Resources Management globally.\n",
        "3. It is based on the Nestlé Management and Leadership Principles and Corporate Business Principles.\n",
        "4. Line managers are responsible for creating an environment where employees are committed to their work and contribute to the company's success.\n",
        "5. HR managers support line managers in aligning business needs with people requirements to optimize performance and ensure exemplary working conditions.\n",
        "6. The HR structure includes Centres of Expertise, Business Partners, and Employee Services to provide specialized services and streamline HR processes.\n",
        "7. The success of the Company depends on attracting, retaining, and developing employees for ongoing and sustainable growth.\n",
        "\n",
        "======\n",
        "\n",
        "page one has in the upper right corner , the nestle logo for good food , good life , can you describe what are the elements of this logo?\n",
        "\n",
        "\n",
        "The Nestlé logo for \"good food, good life\" typically includes a stylized representation of a nest with several small birds inside, symbolizing nurturing and care. The logo may also include the Nestlé name in a distinctive font, along with the company's tagline. The colors of the logo are often a combination of blue, white, and red, reflecting the brand's corporate identity.\n",
        "\n",
        "======\n",
        "\n",
        "section: Employment and working conditions , does the nestle hr policy address any issues concerning the legal rights of employees to form a labor union?\n",
        "\n",
        "output:\n",
        "Based on the provided information, the Nestlé Human Resources Policy does not explicitly mention any issues concerning the legal rights of employees to form a labor union. The policy primarily focuses on the importance of employee engagement, the role of line managers in creating a positive work environment, and the overall objectives of the Human Resources function within Nestlé. It does not specifically address the topic of labor unions or the legal rights of employees to form them.\n",
        "\n",
        "=====\n",
        "interesting interaction here:\n",
        "on page 4 there two main topic in red color , for example , A shared responsibility and Joining Nestle can you see that ?\n",
        "\n",
        "output:\n",
        "I'm sorry, but as an AI text-based model, I am unable to see specific colors or formatting such as red color in the text. However, based on the information provided in the context, it seems like the main topics highlighted are \"A shared responsibility\" and \"Joining Nestle.\" These topics emphasize the importance of individual responsibility, teamwork, and collaboration within Nestle as an organization.\n",
        "\n",
        "\n",
        "from page 4 to page 7 , each page has 2 main topics highlighted , can you tell me what those main topics highlighted are from pages 4 to 7\n",
        "\n",
        "output:\n",
        "\n",
        "Sure, I can provide you with the main topics highlighted on pages 4 to 7 of the document you provided. However, since I cannot directly see the content of the document, I will do my best to give you an accurate response based on the information you have provided.\n",
        "\n",
        "Page 4:\n",
        "1. Business requirements for an agile and innovative company\n",
        "2. Strong willingness to support others and work in multi-skilled teams\n",
        "\n",
        "Page 5:\n",
        "1. Dynamic organization creating a climate of innovation\n",
        "2. Encouragement of taking risks and willingness to correct and learn from mistakes\n",
        "\n",
        "Page 6:\n",
        "1. Combining scope and brand strength of a global company with creativity and knowledge of a local business\n",
        "2. Far-reaching influence and exploration of full long-term potential\n",
        "\n",
        "Page 7:\n",
        "1. Corporate policy - Nestlé on the Move: A flexible and dynamic organization\n",
        "2. Collaboration and support from line managers and employees.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "======\n",
        "\n",
        "on page 4, A shared responsibility and Joining Nestle , can you called those \"headers\"  \n",
        "\n",
        "output:\n",
        "Yes, \"A shared responsibility\" and \"Joining Nestle\" can be called headers on page 4."
      ],
      "metadata": {
        "id": "ejGh2d940Su0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j8giNnhe4aNP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}